# ğŸ§ Human Activity Recognition (HAR) using Live Video and Deep Learning

This project implements a **real-time Human Activity Recognition system** using a pre-trained deep learning model built with TensorFlow/Keras. The system captures live video from a webcam and classifies human actions such as walking, sitting, standing, and more.

---

## ğŸ“š Table of Contents

- [ğŸ§  Project Overview](#-project-overview)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ” Model Details](#-model-details)
- [ğŸš€ How It Works](#-how-it-works)
- [ğŸ“¦ Requirements](#-requirements)
- [â–¶ï¸ How to Run](#ï¸-how-to-run)
- [ğŸ§ª Sample Output](#-sample-output)
- [ğŸ“Œ Notes](#-notes)
- [ğŸ§° Utility Function: Max Subsequence](#-utility-function-max-subsequence)
- [ğŸ“· Screenshots (Optional)](#-screenshots-optional)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)

---

## ğŸ§  Project Overview

The goal of this project is to recognize and classify human activities using a **Convolutional Neural Network (CNN)** trained on image data. The model is capable of identifying various physical states from webcam video in real time.

### Activities Detected

- ğŸ§ Standing  
- ğŸª‘ Sitting  
- ğŸ›ï¸ Sleeping  
- ğŸš¶ Walking  
- ğŸ§— Walking on Stairs  
- â¹ Control (Default/Idle state)

---

---

## ğŸ” Model Details

- **Framework:** TensorFlow / Keras  
- **Input Size:** 150x150 RGB images  
- **Normalization:** Pixel values scaled to `[-1, 1]`  
- **Output:** Softmax classification across **6 activity classes**

---

## ğŸš€ How It Works

1. Captures live video feed using **OpenCV**.
2. Each frame is:
   - Converted to a **PIL image**
   - Resized to **150x150 pixels**
   - Normalized and reshaped to match the model's input format
3. Model predicts the activity from the processed frame.
4. Predicted label is printed to the console with a timestamp.

---

## ğŸ“¦ Requirements

Install the dependencies using pip:

```bash
pip install numpy opencv-python tensorflow pillow
```


## â–¶ï¸ How to Run

Ensure your webcam is connected and functional.

Run the main script:

Copy
Edit

```bash
python main.py
```
Press q to exit the live video feed.

